{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import urllib.request\n",
    "import concurrent\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, InterpolationMode\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Missing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path_from_url(url):\n",
    "    return '-'.join(url.split('/')[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_images():\n",
    "    all_images = pd.read_csv('products.csv')['searchImage'].tolist()\n",
    "    downloaded_images = set(os.listdir('assets'))\n",
    "\n",
    "    print('Download Images: ', len(downloaded_images))\n",
    "\n",
    "    missing_images_set, missing_images = set(), []\n",
    "\n",
    "    for url in all_images:\n",
    "        if get_file_path_from_url(url) in downloaded_images:\n",
    "            continue\n",
    "        if url in missing_images_set:\n",
    "            continue\n",
    "        missing_images.append(url)\n",
    "        missing_images_set.add(url)\n",
    "\n",
    "    print('Missing images: ', len(missing_images))\n",
    "    return missing_images\n",
    "missing_images = get_missing_images()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url):\n",
    "    print(image_url)\n",
    "    file_name = 'assets/' + get_file_path_from_url(image_url)\n",
    "    urllib.request.urlretrieve(image_url, file_name)\n",
    "\n",
    "def multithreaded_download(images, num_threads):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(download_image, image) for image in tqdm(images)]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result(timeout=0.5)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                print(\"A thread took too long and was terminated.\")\n",
    "\n",
    "def singlethreaded_download(images):\n",
    "    for image in images:\n",
    "        download_image(image)\n",
    "# multithreaded_download(missing_images, 30)\n",
    "# singlethreaded_download(missing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_images():\n",
    "    dir = 'assets-224'\n",
    "    images_test = os.listdir(dir)\n",
    "    bad_images = []\n",
    "    for image in tqdm(images_test):\n",
    "        try:\n",
    "            img = Image.open(dir + '/' + image)\n",
    "            np.array(img)\n",
    "        except Exception as e:\n",
    "            print(f'{image} : {e}')\n",
    "            bad_images.append(image)\n",
    "    print('Number of Bad Images: ', len(bad_images))\n",
    "    return bad_images\n",
    "bad_images = find_bad_images()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(files):\n",
    "    transform = Compose([\n",
    "        Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "        CenterCrop(size=(224, 224))\n",
    "    ])\n",
    "    input_folder = 'assets'\n",
    "    output_folder = 'assets-224'\n",
    "    for file in files:\n",
    "        try:\n",
    "            img = Image.open(input_folder + '/' + file)\n",
    "            img = transform(img)\n",
    "            img.save(output_folder + '/' + file)\n",
    "            del img\n",
    "        except Exception as e:\n",
    "            print(e, '===', file)\n",
    "\n",
    "def get_image_files():\n",
    "    processed = set(os.listdir('assets-224'))\n",
    "    image_files = [x for x in os.listdir('assets') if x not in processed and x not in bad_images]\n",
    "    return image_files\n",
    "\n",
    "def multithreaded_resize_images(num_threads=10, batch_size=200):\n",
    "    image_files = get_image_files()\n",
    "    print('received image files')\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            executor.submit(resize_images, image_files[i:i+batch_size])\n",
    "\n",
    "# multithreaded_resize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_image_files = get_image_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "batch_size=500\n",
    "\n",
    "all_images_features = torch.Tensor()\n",
    "input_dir = '/kaggle/input/fashion-224-cropped/assets-224'\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = preprocess(Image.open(input_dir + '/' + image_path)).unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "image_dataset = ImageDataset(all_images)\n",
    "image_dataloader = DataLoader(image_dataset, batch_size=batch_size)\n",
    "\n",
    "for batch_images in tqdm(image_dataloader):\n",
    "    batch_images = batch_images.to(device)\n",
    "\n",
    "    batch_features = model.encode_image(batch_images)\n",
    "    \n",
    "    all_images_features = torch.cat((all_images_features, batch_features), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1440)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('assets/' + truncated_image_files[0])\n",
    "img.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
